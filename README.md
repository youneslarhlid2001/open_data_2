# Pipeline Open Data - TP2

Pipeline complet d'acquisition, transformation et stockage de donnÃ©es Open Data depuis l'API OpenFoodFacts.

## ğŸ“‹ PrÃ©sentation du projet

Ce projet implÃ©mente un pipeline ETL (Extract, Transform, Load) pour rÃ©cupÃ©rer des donnÃ©es nutritionnelles depuis l'API OpenFoodFacts, les nettoyer et les stocker au format Parquet.

### Choix de l'API

**OpenFoodFacts** est une base de donnÃ©es collaborative sur les produits alimentaires :
- API REST publique sans authentification
- DonnÃ©es riches : informations nutritionnelles, Nutri-Score, NOVA, etc.
- Documentation complÃ¨te : https://world.openfoodfacts.org/api/v2
- Endpoint utilisÃ© : `/search` avec pagination

## ğŸ—ï¸ Structure du projet

```
tp2-pipeline/
â”œâ”€â”€ pipeline/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py          # Configuration centralisÃ©e
â”‚   â”œâ”€â”€ fetcher.py         # RÃ©cupÃ©ration des donnÃ©es (API)
â”‚   â”œâ”€â”€ transformer.py     # Transformation et nettoyage
â”‚   â”œâ”€â”€ storage.py         # Stockage Parquet
â”‚   â””â”€â”€ main.py            # Orchestration du pipeline
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/               # DonnÃ©es brutes JSON
â”‚   â””â”€â”€ processed/         # DonnÃ©es nettoyÃ©es Parquet
â””â”€â”€ README.md
```

## ğŸ“¦ Installation (backend)

PrÃ©requis : Python 3.11+, pip.

```bash
pip install -r requirements.txt
```

## ğŸš€ DÃ©marrage rapide (recommandÃ© pour la soutenance)

1) Lancer lâ€™API FastAPI (backend)  
```bash
uvicorn api:app --reload --port 8000
```

2) Lancer le frontend React (Vite)  
```bash
cd frontend
npm install      # premiÃ¨re fois
npm run dev -- --host --port 5174 --strictPort
```

3) Ouvrir lâ€™UI : http://localhost:5174  
   - Cliquer â€œLancer le pipelineâ€ â†’ collecte, nettoyage, stockage  
   - Cliquer â€œRafraÃ®chir lâ€™aperÃ§uâ€ â†’ tableau (50 lignes) + KPI + graphes  
   - â€œTÃ©lÃ©charger le Parquetâ€ â†’ rÃ©cupÃ¨re le dernier fichier traitÃ©

## ğŸš€ Utilisation

### Ã‰tat actuel du projet

**Modules disponibles :**
- âœ… `config.py` : Configuration centralisÃ©e
- âœ… `fetcher.py` : RÃ©cupÃ©ration des donnÃ©es avec pagination et retry
- âœ… `transformer.py` : Transformation et nettoyage (pandas)
- âœ… `storage.py` : Stockage JSON/Parquet
- âœ… `main.py` : Orchestration du pipeline
- âœ… `api.py` : API FastAPI (lancement pipeline, preview, stats, download)
- âœ… Tests unitaires (pytest)
- âœ… Dockerfile pour lâ€™API/pipeline

### Tester rapidement (fetch + pipeline)

#### Fetcher seul

```python
import logging
from pipeline.fetcher import fetch_page, fetch_all_data

logging.basicConfig(level=logging.INFO)

data = fetch_page(1)
print(f"Page 1 : {len(data.get('products', []))} produits")

all_products = fetch_all_data()
print(f"Total : {len(all_products)} produits")
```

#### ExÃ©cution du pipeline complet

```bash
python -m pipeline.main
```

Sorties :
- JSON brut horodatÃ© dans `data/raw/`
- Parquet nettoyÃ© dans `data/processed/`

#### API FastAPI (pilotage / visualisation)

```bash
uvicorn api:app --reload --port 8000
```

Endpoints principaux :
- `POST /run` : lance le pipeline complet (fetch â†’ transform â†’ save)
- `GET /preview?limit=50` : aperÃ§u des donnÃ©es nettoyÃ©es
- `GET /stats` : agrÃ©gats Nutri-Score / NOVA + total de lignes
- `GET /download` : tÃ©lÃ©charge le dernier Parquet
- `GET /health` : ping de santÃ©

#### Frontend React (Vite)

```bash
cd frontend
npm install
npm run dev -- --host --port 5174 --strictPort
```

Configuration :
- API cible via `VITE_API_URL` (dÃ©faut `http://localhost:8000`)
- Timeout UI via `VITE_API_TIMEOUT_MS` (dÃ©faut 180000 ms pour laisser finir le pipeline)
- Table (TanStack) + graphes (Recharts)

### ğŸ§ª Tests

```bash
pytest
```

Les tests couvrent notamment la transformation / nettoyage (normalisation, dÃ©duplication, cast numÃ©riques).

### ğŸ³ Docker (API + pipeline)

Build :
```bash
docker build -t openfoodfacts-pipeline .
```

Run :
```bash
docker run -p 8000:8000 openfoodfacts-pipeline
```

Endpoints disponibles comme en local : `/run`, `/preview`, `/stats`, `/download`, `/health`.

## ğŸ“Š DonnÃ©es rÃ©cupÃ©rÃ©es

Le pipeline rÃ©cupÃ¨re les champs suivants pour chaque produit :

- `code` : Code-barres du produit
- `product_name` : Nom du produit
- `brands` : Marques
- `categories` : CatÃ©gories
- `nutriscore_grade` : Note Nutri-Score (A Ã  E)
- `nova_group` : Groupe NOVA (1 Ã  4)
- `energy_100g` : Ã‰nergie pour 100g (kcal)
- `fat_100g` : MatiÃ¨res grasses pour 100g (g)
- `sugars_100g` : Sucres pour 100g (g)
- `salt_100g` : Sel pour 100g (g)
- `proteins_100g` : ProtÃ©ines pour 100g (g)

## âš™ï¸ Configuration

Les paramÃ¨tres sont centralisÃ©s dans `pipeline/config.py` :

- **Pagination** : 100 produits par page, maximum 10 pages
- **CatÃ©gorie** : `en:beverages` (boissons)
- **Retry** : 3 tentatives avec backoff exponentiel
- **Rate limiting** : 0.5 seconde entre les requÃªtes
- **Timeout** : 30 secondes par requÃªte

## ğŸ”§ FonctionnalitÃ©s

### Module fetcher.py

- âœ… RÃ©cupÃ©ration paginÃ©e automatique
- âœ… Gestion des erreurs rÃ©seau avec retry (tenacity)
- âœ… Rate limiting pour respecter l'API
- âœ… Client HTTP rÃ©utilisable pour performance
- âœ… Logging structurÃ©
- âœ… Barre de progression (tqdm)

### Module transformer.py

- Nettoyage pandas (textes normalisÃ©s, minuscules, espaces)
- Cast des types numÃ©riques (coerce -> NaN)
- Suppression des doublons sur le code produit
- Suppression des lignes vides (nom/marque manquants)

### Module storage.py

- Sauvegarde JSON brut horodatÃ© dans `data/raw/`
- Sauvegarde Parquet compressÃ© (snappy) dans `data/processed/`
- Chargement du dernier Parquet disponible

### Module main.py

- Orchestration complÃ¨te (fetch â†’ transform â†’ store)
- Logging lisible
- ExÃ©cutable via `python -m pipeline.main`

### API FastAPI (api.py)

- Routes `POST /run`, `GET /preview`, `GET /stats`, `GET /download`, `GET /health`
- CORS ouvert pour le frontend

### Frontend React (frontend/)

- Vite + React 18
- Table TanStack + graphiques Recharts
- Consomme lâ€™API (config via `VITE_API_URL`)

## ğŸ“ Exemple de sortie

Une fois le pipeline complet exÃ©cutÃ©, vous obtiendrez :

```
data/
â”œâ”€â”€ raw/
â”‚   â””â”€â”€ products_2025-12-16_21-30-45.json
â””â”€â”€ processed/
    â””â”€â”€ products_2025-12-16_21-30-45.parquet
```

## ğŸ› DÃ©pannage

### Erreur d'import

Assurez-vous d'Ãªtre Ã  la racine du projet et que Python trouve le module :

```bash
# VÃ©rifier la structure
ls pipeline/

# Tester l'import
python -c "import pipeline.config; print('OK')"
```

### Erreur rÃ©seau

Le module `fetcher.py` gÃ¨re automatiquement les erreurs rÃ©seau avec retry. Si les erreurs persistent :
- VÃ©rifiez votre connexion Internet
- Augmentez `REQUEST_TIMEOUT` dans `config.py`
- VÃ©rifiez que l'API OpenFoodFacts est accessible

### Pipeline trop long / timeout cÃ´tÃ© UI
- Le frontend utilise un timeout long (180 s). Si besoin, rÃ©duisez temporairement le volume pour un test rapide dans `pipeline/config.py` (ex. `MAX_PAGES=3`, `PAGE_SIZE=50`), puis remettez `10` / `100` pour la version finale notÃ©e.
- Sur rÃ©seau lent ou API lente, laissez le temps au `/run` dâ€™aboutir ; les retries sont gÃ©rÃ©s par `tenacity`.

## ğŸ“š Documentation

- API OpenFoodFacts : https://world.openfoodfacts.org/api/v2
- Documentation httpx : https://www.python-httpx.org/
- Documentation pandas : https://pandas.pydata.org/
- Documentation pyarrow : https://arrow.apache.org/docs/python/

## ğŸ‘¤ Auteur

Projet rÃ©alisÃ© dans le cadre du TP2 - Open Data

